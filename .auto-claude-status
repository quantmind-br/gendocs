{
  "active": true,
  "spec": "007-stream-llm-api-responses-instead-of-buffering-enti",
  "state": "building",
  "subtasks": {
    "completed": 6,
    "total": 17,
    "in_progress": 1,
    "failed": 0
  },
  "phase": {
    "current": "Implement OpenAI Streaming",
    "id": null,
    "total": 2
  },
  "workers": {
    "active": 0,
    "max": 1
  },
  "session": {
    "number": 8,
    "started_at": "2025-12-29T02:38:49.001429"
  },
  "last_update": "2025-12-29T03:02:07.320043"
}