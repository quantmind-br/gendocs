# Gendocs Go Implementation

This is the Go port of the AI Documentation Generator. The Go version aims to provide better performance, easier distribution, and simplified deployment while maintaining complete feature parity with the Python version.

## Current Status

**Phase: Foundation Complete** ðŸ—ï¸

The core infrastructure has been implemented and the CLI compiles successfully. This is a work in progress following the detailed implementation plan in `../PLAN.md`.

### What's Implemented

âœ… **Phase 1: Foundation**
- Project structure with Go modules
- Error handling system (14 exception types, rich error context)
- Structured logging (zap with file + console output)
- Configuration system (multi-source: CLI > YAML > env > defaults)

âœ… **Phase 2: LLM Integration**
- HTTP retry client with exponential backoff
- LLM provider interface
- OpenAI client implementation (including OpenAI-compatible APIs)

âœ… **Phase 3: Tools & Concurrency**
- FileReadTool (with pagination support)
- ListFilesTool (recursive directory listing)
- Worker pool (semaphore-based concurrency control)

âœ… **Phase 5: CLI**
- Cobra CLI framework
- `gendocs analyze` command with all flags
- Help system

### What's Still Needed

ðŸ”„ **Phase 4: Agents**
- Prompt system (Jinja2 â†’ Go template conversion)
- Base agent with tool calling loop
- 5 sub-agents (Structure, Dependency, DataFlow, RequestFlow, API)
- DocumenterAgent (README generation)
- AIRulesGeneratorAgent (CLAUDE.md, AGENTS.md, .cursor/rules/)

ðŸ”„ **Phase 5: Handlers**
- AnalyzeHandler
- ReadmeHandler
- AIRulesHandler
- CronjobHandler

ðŸ”„ **Phase 6: Remaining LLM Providers**
- Anthropic Claude client
- Google Gemini client (standard API)
- Google Gemini via Vertex AI

ðŸ”„ **Phase 6: GitLab Integration**
- GitLab API client
- Project filtering logic
- Repository cloning
- Branch creation, commit, push
- Merge request creation

ðŸ”„ **Phase 7: TUI Config Wizard**
- Bubble Tea configuration UI
- Provider selection
- API key input (masked)
- Save to ~/.gendocs.yaml

## Building

```bash
cd gendocs
go build -o gendocs .
```

## Running

```bash
# Show help
./gendocs --help

# Show analyze command help
./gendocs analyze --help

# Analyze a codebase (not yet fully functional)
./gendocs analyze --repo-path ../
```

## Configuration

The Go version supports the same configuration sources as the Python version:

1. **CLI arguments** (highest priority)
2. **`.ai/config.yaml`** (project-specific)
3. **`~/.gendocs.yaml`** (global user config, from TUI)
4. **Environment variables**
5. **Defaults** (lowest priority)

### Environment Variables

```bash
# Analyzer configuration
export ANALYZER_LLM_PROVIDER="openai"  # openai, anthropic, gemini
export ANALYZER_LLM_MODEL="gpt-4o"
export ANALYZER_LLM_API_KEY="sk-..."
export ANALYZER_LLM_BASE_URL="https://api.openai.com/v1"  # optional
export ANALYZER_AGENT_RETRIES=2
export ANALYZER_LLM_TIMEOUT=180
export ANALYZER_LLM_MAX_TOKENS=8192
export ANALYZER_LLM_TEMPERATURE=0.0
export ANALYZER_MAX_WORKERS=0  # 0 = auto-detect CPU count
```

See `../PLAN.md` for the complete list of 40+ environment variables.

## Project Structure

```
gendocs/
â”œâ”€â”€ cmd/                    # CLI commands (Cobra)
â”‚   â”œâ”€â”€ root.go            # Root command
â”‚   â””â”€â”€ analyze.go         # Analyze subcommand
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ agents/            # AI agents (not yet implemented)
â”‚   â”œâ”€â”€ config/            # Configuration loading
â”‚   â”œâ”€â”€ errors/            # Error handling (14 exception types)
â”‚   â”œâ”€â”€ logging/           # Structured logging (zap)
â”‚   â”œâ”€â”€ llm/               # LLM provider abstraction
â”‚   â”‚   â”œâ”€â”€ client.go      # LLM client interface
â”‚   â”‚   â”œâ”€â”€ retry_client.go # HTTP with retry logic
â”‚   â”‚   â””â”€â”€ openai.go      # OpenAI implementation
â”‚   â”œâ”€â”€ tools/             # Agent tools
â”‚   â”‚   â”œâ”€â”€ base.go        # Tool base with retry
â”‚   â”‚   â”œâ”€â”€ file_read.go   # File reading tool
â”‚   â”‚   â””â”€â”€ list_files.go  # Directory listing tool
â”‚   â”œâ”€â”€ worker_pool/       # Concurrent task execution
â”‚   â”‚   â””â”€â”€ pool.go        # Semaphore-based pool
â”‚   â””â”€â”€ tui/               # TUI config wizard (not yet implemented)
â”œâ”€â”€ prompts/               # YAML prompt templates (not yet added)
â”œâ”€â”€ main.go
â”œâ”€â”€ go.mod
â””â”€â”€ README.md
```

## Architecture

The Go implementation follows the same **Handler-Agent Architecture** as the Python version:

```
CLI Layer (Cobra)
    â†“
Handler Layer (orchestration)
    â†“
Agent Layer (AI logic)
    â†“
Tools (file system access)
    â†“
Infrastructure (logging, retry, worker pool)
```

## Implementation Plan

See `../PLAN.md` for the complete implementation roadmap:

1. **Phase 1-3**: âœ… Foundation (Complete)
2. **Phase 4**: Agents (In Progress - foundation laid)
3. **Phase 5**: Handlers (In Progress - CLI working)
4. **Phase 6**: GitLab Integration (Pending)
5. **Phase 7**: TUI Config (Pending)
6. **Phase 8**: Testing & Validation (Pending)

**Estimated Timeline**: 13 weeks total (3.25 months)

**Current Progress**: ~40% (Phases 1-3 complete, Phase 5 started)

## Development

### Prerequisites

- Go 1.22 or later
- Access to LLM provider API (OpenAI recommended during development)

### Running Tests

```bash
go test ./...
```

### Linting

```bash
go fmt ./...
go vet ./...
```

## License

Same as the parent project.

## Contributing

This is a work in progress. Refer to `../PLAN.md` for guidance on contributing to specific phases.
